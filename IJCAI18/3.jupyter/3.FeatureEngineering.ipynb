{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#数据处理\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "#可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#ML\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, GradientBoostingRegressor, \n",
    "                              RandomForestClassifier, RandomForestRegressor)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果为True，则对训练集合进行处理\n",
    "# 如果为False，则对测试集合进行处理\n",
    "flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.数据载入、对齐、排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "data = pd.read_pickle('data/round1_train1')\n",
    "\n",
    "\n",
    "if(flag is False):\n",
    "    data_test = pd.read_pickle('data/round1_test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 给test数据拼接一个f26特征\n",
    "if(flag is False):\n",
    "    data_test = pd.concat([data_test,pd.Series([0] * len(data_test))], axis = 1)\n",
    "    data_test = data_test.rename({0:'f26'},axis = 'columns')\n",
    "\n",
    "# 给train数据按时间排序\n",
    "data.sort_values(['f16'],inplace = True)\n",
    "data.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.特征转换、衍生\n",
    "## 3.1离散数据\n",
    "### 3.1.1将出现次数少的值合并到统一类别中\n",
    "- f6：将10（456）、2（347）、1（85）、11（21）、0（12）、17（1）、16（1）这几个取值单独拉出一个类。\n",
    "- f9：将8（449）、7（245）、0（123）、6（116）、5（63）、4（33）3（11）、2（5）、1（1）这几个取值单独拉出一个类。\n",
    "- f20：将23（353）、4（266）、2（87）、3（80）、1（20）、0（7）、25（4）这几个取值单独拉出一个类。\n",
    "- f22：将5002（477）、5020（357）、5000（81）、5019（70）、5001（60）、4999（7）这几个取值单独拉出一个类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2onehot/dummy-trap\n",
    "- 如果类别特征本身有顺序（例：优秀、良好、合格、不合格），那么可以保留单列自然数编码。如果类别特征没有明显的顺序（例：红、黄、蓝）则使用one-hot。\n",
    "- f6广告商品的价格等级、f9广告商品被展示次数的等级、f11用户的预测性别编号、f12用户的预测年龄等级、f13用户的预测职业编号、f14用户的星级编号\n",
    "- f7、f8、f17、f20、f22不确定\n",
    "- sklearn.preprocessing.OneHotEncoder()\n",
    "\n",
    "#### 3.1.2.1f11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def onehot_f11(data):\n",
    "    temp = pd.get_dummies(data['f11'])  \n",
    "    temp = temp.rename({0.0:'f11:woman',1.0:'f11:man',2.0:'f11:family',3.0:'f11:other'},axis = 'columns')\n",
    "    return pd.concat([data.loc[:,'f0':'f11'],temp,data.loc[:,'f12':'f26']], axis = 1)\n",
    "\n",
    "data = onehot_f11(data)\n",
    "if(flag is False):\n",
    "    data_test = onehot_f11(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2f13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_f13(data):\n",
    "    temp = pd.get_dummies(data['f13'])  \n",
    "    temp = temp.rename({2002.0:'f13:2002.0',2003.0:'f13:2003.0',2004.0:'f13:2004.0',2005.0:'f13:2005.0'},axis = 'columns')\n",
    "    return pd.concat([data.loc[:,'f0':'f13'],temp,data.loc[:,'f14':'f26']], axis = 1)\n",
    "\n",
    "data = onehot_f13(data)\n",
    "if(flag is False):\n",
    "    data_test = onehot_f13(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.3f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f0', 'f1', 'f2', 'f2:1', 'f2:2', 'f2:3', 'f3', 'f4', 'f5', 'f6', 'f7',\n",
      "       'f8', 'f9', 'f10', 'f11', 'f11:woman', 'f11:man', 'f11:family',\n",
      "       'f11:other', 'f12', 'f13', 'f13:2002.0', 'f13:2003.0', 'f13:2004.0',\n",
      "       'f13:2005.0', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21',\n",
      "       'f22', 'f23', 'f24', 'f25', 'f26'],\n",
      "      dtype='object')\n",
      "Index(['f0', 'f1', 'f2', 'f2:1', 'f2:2', 'f2:3', 'f3', 'f4', 'f5', 'f6', 'f7',\n",
      "       'f8', 'f9', 'f10', 'f11', 'f11:woman', 'f11:man', 'f11:family',\n",
      "       'f11:other', 'f12', 'f13', 'f13:2002.0', 'f13:2003.0', 'f13:2004.0',\n",
      "       'f13:2005.0', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21',\n",
      "       'f22', 'f23', 'f24', 'f25', 'f26'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def split_f2(data):\n",
    "    # 切分\n",
    "    data = pd.concat([data.loc[:,'f0':'f2'],data['f2'].astype(np.str).str.split(';', expand=True),data.loc[:,'f3':'f26']], axis = 1)\n",
    "    data.rename({0:'f2:1',1:'f2:2',2:'f2:3'}, axis='columns',inplace = True)\n",
    "    print(data.columns)\n",
    "    # 类型转换\n",
    "    data['f2:3'].fillna('-1',inplace = True)\n",
    "    data['f2:1'] = data['f2:1'].astype('int')\n",
    "    data['f2:2'] =data['f2:2'].astype('int')\n",
    "    data['f2:3'] = data['f2:3'].astype('int')\n",
    "\n",
    "    # 丢弃f2:1，对f2:2、f2:3进行onehot编码\n",
    "    temp = pd.get_dummies(data['f2:2'],prefix = 'f2:2')  \n",
    "    data = pd.concat([data.loc[:,'f0':'f2:2'],temp,data.loc[:,'f2:3':'f26']], axis = 1)\n",
    "\n",
    "    temp = pd.get_dummies(data['f2:3'],prefix = 'f2:3')  \n",
    "    return pd.concat([data.loc[:,'f0':'f2:3'],temp,data.loc[:,'f3':'f26']], axis = 1)\n",
    "\n",
    "data = split_f2(data)\n",
    "if(flag is False):\n",
    "    data_test = split_f2(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.4f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def onehot_f5(data):\n",
    "#     temp = pd.get_dummies(data['f5'],prefix='f5')  \n",
    "#     return pd.concat([data.loc[:,'f0':'f5'],temp,data.loc[:,'f6':'f26']], axis = 1)\n",
    "\n",
    "# data = onehot_f5(data)\n",
    "# if(flag is False):\n",
    "#     data_test = onehot_f5(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = pd.concat([data.loc[:,'f0':'f5_5.326000431362992e+18'],pd.Series([np.nan] * len(data)),data.loc[:,'f5_5.727554123450503e+18':'f26']],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = data.rename({0:'f5_5.559622052853629e+18'},axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将f11、f13进行onehot编码后，xgboost的验证集loss由0.084306减小到0.084273\n",
    "- 将f2;2用onehot表示后，xgboost的验证集loss由0.0775减小到0.07373\n",
    "- 将f5用onehot表示后，xgboost的验证集loss由0.086977提高到0.087148，没用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3自然数编码\n",
    "- 消耗内存小，训练时间快，但是相比one-hot特征的质量不高，含了一个假设：不同的类别之间，存在一种顺序关系。\n",
    "- pd.Factorize()\n",
    "- sklearn.LabelEncoder()\n",
    "\n",
    "### 3.1.4聚类编码\n",
    "- 和独热编码相比，聚类编码试图充分利用每一列0与1的信息表达能力。聚类编码时一般需要特定的专业知识（domain knowledge），例如ZIP码可以根据精确度分层为ZIP3、ZIP4、ZIP5、ZIP6，然后按层次进行编码。\n",
    "\n",
    "- （我个人尚未使用过这种方法，仅在读论文的时候看到了类似的思路，所以暂时不知道对于各种算法而言效果如何。）\n",
    "\n",
    "\n",
    "## 3.2连续数据\n",
    "### 3.2.1scaling：分布太宽，做一下scaling，如：标准化、归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "# def scaling(data):\n",
    "#     for i in range(0,8):\n",
    "#         data['f12'] = data['f12'].replace(1000. + i,0 + i)\n",
    "#     for i in range(0,11):\n",
    "#         data['f14'] = data['f14'].replace(3000. + i,0 + i)\n",
    "#     for i in range(0,20):\n",
    "#         data['f17'] = data['f17'].replace(4001. + i,0 + i)\n",
    "#     for i in range(0,22):\n",
    "#         data['f22'] = data['f22'].replace(4999. + i,0 + i)\n",
    "#         return data\n",
    "\n",
    "# data = scaling(data)\n",
    "# if(flag is False):\n",
    "#     data_test = scaling(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将f112、f14、f17、f22进行范围缩放后，xgboost的验证集loss由0.0775没变，没用。\n",
    "\n",
    "### 3.2.2正态化：对偏度大于0.75的数值特征（长尾分布）\n",
    "- 用log1p函数进行转化使其更加服从高斯分布\n",
    "np.log1p(train.SalePrice)\n",
    "- Box-Cox变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f7:2 f8:2.5 f9:5 f20:1.5\n",
    "# def boxcox(data):\n",
    "#     data['f7'] = boxcox1p(data['f7'],2)\n",
    "#     data['f8'] = boxcox1p(data['f8'],2.5)\n",
    "#     data['f9'] = boxcox1p(data['f9'],5)\n",
    "#     data['f20'] = boxcox1p(data['f20'],1.5)\n",
    "#     return data\n",
    "\n",
    "# data = boxcox(data)\n",
    "# if(flag is False):\n",
    "#     data_test = boxcox(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3Binning：连续变量离散化\n",
    "- 只有在了解属性的领域知识的基础，确定属性能够划分成简洁的范围时分箱才有意义，即所有的数值落入一个分区时能够呈现出共同的特征。\n",
    "- 当不想让模型总是尝试区分值之间是否太近时，分区可以避免出现过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正态化后，xgboost的验证集loss不变，没用\n",
    "\n",
    "### 3.2.4时间数据的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_f16(data):\n",
    "    now = pd.to_datetime(data['f16'],unit='s',utc = True)\n",
    "    \n",
    "    size = len(data)\n",
    "    # year = pd.Series([-1] * 477303)\n",
    "    # month = pd.Series([-1] * 477303)\n",
    "    day = pd.Series([-1] * size)\n",
    "    hour = pd.Series([-1] * size)\n",
    "    minute = pd.Series([-1] * size)\n",
    "    second = pd.Series([-1] * size)\n",
    "    dayofweek = pd.Series([-1] * size)\n",
    "    dayofyear = pd.Series([-1] * size)\n",
    "\n",
    "    for i in range(len(data['f16'])):\n",
    "    #     year[i] = data['f16'][0].year\n",
    "    #     month[i] = data['f16'][0].month\n",
    "        day[i] = now[i].day\n",
    "        hour[i] = now[i].hour\n",
    "        minute[i] = now[i].minute\n",
    "        second[i] = now[i].second\n",
    "        dayofweek[i] = now[i].dayofweek\n",
    "        dayofyear[i] = now[i].dayofyear\n",
    "    data = pd.concat([data.loc[:,'f0':'f16'],day,hour,minute,second,dayofweek,dayofyear,data.loc[:,'f17':'f26']], axis = 1)\n",
    "    data.rename({'f26':'label'}, axis='columns',inplace = True)\n",
    "    data.rename({0:'f16:day',1:'f16:hour',2:'f16:minute',3:'f16:second',4:'f16:dayofweek',5:'f16:dayofyear'}, axis='columns',inplace = True)\n",
    "    return data\n",
    "\n",
    "data = transform_f16(data)\n",
    "if(flag is False):\n",
    "    data_test = transform_f16(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 转换时间f16为多个特征并删除特征f16后，xgboost的验证集loss较明显的降低\n",
    "- 加入dayofweek特征后，xgboost的验证集loss没变，没用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3高势集数据\n",
    "### 3.3.1拆分题目中的属性（f2、f3、f18）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3高势集类别（High Categorical）进行经验贝叶斯转换成数值feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4平均数编码\n",
    "- 平均数编码（mean encoding），针对高基数类别特征的有监督编码。当一个类别特征列包括了极多不同类别时（如家庭地址，动辄上万）时，可以采用。优点：和独热编码相比，节省内存、减少算法计算时间、有效增强模型表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将f2属性拆分成三个子属性后，xgboost的验证集loss不变，没用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.特征组合\n",
    "## 4.1加入统计比例数据\n",
    "### 4.1.1f19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_f19_label(dataall,data,i):\n",
    "    temp = dataall[dataall['f16:day'] < i + 17].groupby(['f19']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f19'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "temp = pd.Series([])\n",
    "for i in range(8):\n",
    "    now = get_f19_label(data,data[data['f16:day'] == i + 17],i)\n",
    "    temp = temp.append(now)\n",
    "\n",
    "data_combination = pd.concat([temp], axis = 1)\n",
    "data_combination.rename({0:'f19-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_f19_label_test(dataall,data,i):\n",
    "    temp = dataall.groupby(['f19']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f19'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "if(flag is False):\n",
    "    temp = pd.Series([])\n",
    "    temp = get_f19_label_test(data,data_test,i)\n",
    "\n",
    "    data_combination_test = pd.concat([temp], axis = 1)\n",
    "    data_combination_test.rename({'f19':'f19-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_f1_label(dataall,data,i):\n",
    "    temp = dataall[dataall['f16:day'] < i + 17].groupby(['f1']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f1'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "temp = pd.Series([])\n",
    "for i in range(8):\n",
    "    now = get_f1_label(data,data[data['f16:day'] == i + 17],i)\n",
    "    temp = temp.append(now)\n",
    "\n",
    "data_combination = pd.concat([data_combination,temp], axis = 1)\n",
    "data_combination.rename({0:'f1-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_f1_label_test(dataall,data,i):\n",
    "    temp = dataall.groupby(['f1']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f1'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "if(flag is False):\n",
    "    temp = pd.Series([])\n",
    "    temp = get_f1_label_test(data,data_test,i)\n",
    "\n",
    "    data_combination_test = pd.concat([data_combination_test,temp], axis = 1)\n",
    "    data_combination_test.rename({'f1':'f1-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_f4_label(dataall,data,i):\n",
    "    temp = dataall[dataall['f16:day'] < i + 17].groupby(['f4']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f4'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "temp = pd.Series([])\n",
    "for i in range(8):\n",
    "    now = get_f4_label(data,data[data['f16:day'] == i + 17],i)\n",
    "    temp = temp.append(now)\n",
    "    \n",
    "data_combination = pd.concat([data_combination.loc[:,'f1-label'],temp,data_combination['f19-label']], axis = 1)\n",
    "data_combination.rename({0:'f4-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_f4_label_test(dataall,data,i):\n",
    "    temp = dataall.groupby(['f4']).apply(lambda x:x['label'].sum()/len(x))  # 前n天出现商品的转化率=\n",
    "    return data['f4'].apply(lambda x,temp:temp[x] if x in temp else -1,args = (temp,))\n",
    "\n",
    "if(flag is False):\n",
    "    temp = pd.Series([])\n",
    "    temp = get_f4_label_test(data,data_test,i)\n",
    "\n",
    "    data_combination_test = pd.concat([data_combination_test.loc[:,'f1-label'],temp,data_combination_test['f19-label']], axis = 1)\n",
    "    data_combination_test.rename({'f4':'f4-label'}, axis='columns',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将f19进行转换为点击概率后，xgboost的验证集loss由0.084273减小到0.080542\n",
    "- 将f1进行转换为点击概率后，xgboost的验证集loss由0.080542减小到0.0775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2时间序列：\n",
    "- 把昨天的特征加入今天的特征，或者把和昨天相比，特征数值的改变量加入今天的特征。\n",
    "\n",
    "## 4.3特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data.loc[:,'f0':'f25'],data_combination,data.loc[:,'label']],axis = 1)\n",
    "if(flag is False):\n",
    "    data_test = pd.concat([data_test.loc[:,'f0':'f25'],data_combination_test,data_test.loc[:,'label']],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.特征选择\n",
    "- 除非万不得已，不要用PCA或者LDA降维，直接减原始特征就行了。\n",
    "\n",
    "## 5.1质量不好的特征\n",
    "- 缺失的行特别多，弃用该列，超过15%缺失的特征应该予以删除！\n",
    "- 质量都不错，最多的f12（0.027）\n",
    "\n",
    "## 5.2冗余特征（相关性强的保留一个）\n",
    "- 有些 Feature 之间可能存在线性关系，影响 Model 的性能。\n",
    "- Feature越少，训练越快。\n",
    "\n",
    "## 5.3无关特征\n",
    "- f0样本编号：近似唯一\n",
    "- f1广告商品编号\n",
    "- f10用户编号\n",
    "- f15上下文信息编号：完全唯一\n",
    "- f19店铺编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.drop('f16',axis = 1)\n",
    "data.drop(['f2','f2:1','f2:2','f2:3','f3','f11','f13','f18'], axis=1,inplace = True)\n",
    "if(flag is False):\n",
    "    data_test.drop(['f2','f2:1','f2:2','f2:3','f3','f11','f13','f18','label'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.标签处理\n",
    "- 上采样、下采样、分层采样。\n",
    "\n",
    "# 8.保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2:2_22731265849056483', 'f2:2_509660095530134768',\n",
       "       'f2:2_1968056100269760729', 'f2:2_2011981573061447208',\n",
       "       'f2:2_2436715285093487584', 'f2:2_2642175453151805566',\n",
       "       'f2:2_3203673979138763595', 'f2:2_4879721024980945592',\n",
       "       'f2:2_5755694407684602296', 'f2:2_5799347067982556520',\n",
       "       'f2:2_7258015885215914736', 'f2:2_8277336076276184272',\n",
       "       'f2:2_8710739180200009128', 'f2:3_-1', 'f2:3_6233669177166538628',\n",
       "       'f2:3_8868887661186419229', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11:woman', 'f11:man', 'f11:family', 'f11:other', 'f12', 'f13:2002.0',\n",
       "       'f13:2003.0', 'f13:2004.0', 'f13:2005.0', 'f14', 'f15', 'f16',\n",
       "       'f16:day', 'f16:hour', 'f16:minute', 'f16:second', 'f16:dayofweek',\n",
       "       'f16:dayofyear', 'f17', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25',\n",
       "       'f1-label', 'f4-label', 'f19-label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('data/round1_train2')\n",
    "\n",
    "if(flag is False):\n",
    "    data_test.to_pickle('data/round1_test2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
